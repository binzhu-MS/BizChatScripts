{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4781a110",
   "metadata": {},
   "source": [
    "# Reasoning Model Multi-Hop Comparison Report\n",
    "\n",
    "This Jupyter notebook processes SEVAL job data and generates detailed multi-hop comparison reports on reasoning models across control and treatment experiments.\n",
    "\n",
    "**Getting Started**: When you run the configuration cell (cell 4), you can modify the following settings:\n",
    "\n",
    "1. **SEVAL Job ID** (e.g., '133560') – The job ID to analyze\n",
    "2. **Top-k Values** – List of top-k values to analyze (e.g., [1, 3, 5]) for ranking metrics\n",
    "3. **Threads** – Number of threads for parallel processing\n",
    " \n",
    "**Data Structure**:\n",
    "The notebook uses the **unified extraction approach** which reads from raw DCG files:\n",
    "```\n",
    "seval_data/\n",
    "  {job_id}_metrics/                      # Contains raw DCG files with EvaluationData\n",
    "```\n",
    "\n",
    "**What This Notebook Does**:\n",
    "- Extracts conversation details AND CiteDCG scores from raw DCG files (unified approach)\n",
    "- Builds per-utterance statistics aggregated by hop index\n",
    "- Creates comprehensive comparison plots showing:\n",
    "  - Hop-by-hop score progression (including/excluding empty hops)\n",
    "  - Single-hop vs multi-hop performance analysis\n",
    "  - Control vs treatment experiment comparisons\n",
    "  - Three-curve utterance counts (with scores at hop, scores elsewhere, no scores anywhere)\n",
    "- Exports detailed statistics to CSV for further analysis\n",
    "\n",
    "**Processing Behavior**:\n",
    "- Uses the **unified DCG extraction** approach which extracts both conversation details and CiteDCG scores from a single source (raw CiteDCG files)\n",
    "- Statistics and plots are always regenerated for consistency\n",
    "\n",
    "**Output**: All results are saved to `results/{job_id}_unified_statistics_plots/` including:\n",
    "- Statistics JSON files with hop-level aggregations\n",
    "- PNG plot images for visualization\n",
    "- CSV exports for Excel/data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a12f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreload for development\n",
    "# This automatically reloads imported modules when they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(\"✓ Autoreload enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc8e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries and configure Python path for module imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown, Image\n",
    "\n",
    "# Add the seval directory to the path\n",
    "seval_dir = Path.cwd()\n",
    "if str(seval_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(seval_dir))\n",
    "\n",
    "# Add the workspace root to the path for utils module\n",
    "workspace_root = seval_dir.parent.parent  # c:\\working\\BizChatScripts\n",
    "if str(workspace_root) not in sys.path:\n",
    "    sys.path.insert(0, str(workspace_root))\n",
    "\n",
    "print(f\"✓ Added to path: {seval_dir}\")\n",
    "print(f\"✓ Added to path: {workspace_root}\")\n",
    "print(\"✓ Modules loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee27788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Modify these values as needed\n",
    "JOB_ID = \"133560\"\n",
    "TOP_K_LIST = [1, 3, 5]  # Top-k values to analyze\n",
    "NUM_THREADS = 8\n",
    "\n",
    "# Base directories\n",
    "BASE_DIR = Path.cwd()\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Job ID: {JOB_ID}\")\n",
    "print(f\"  Experiment: both (control + treatment)\")\n",
    "print(f\"  Top-k values: {TOP_K_LIST}\")\n",
    "print(f\"  Threads: {NUM_THREADS}\")\n",
    "print(f\"  Output directory: {RESULTS_DIR}\")\n",
    "print()\n",
    "print(\"✓ Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad2bb6",
   "metadata": {},
   "source": [
    "## Step 1: Run Unified SEVAL Processing Pipeline\n",
    "\n",
    "This uses the **unified extraction approach** which extracts both conversation details and CiteDCG scores from raw DCG files in a single pass.\n",
    "\n",
    "**Steps performed**:\n",
    "1. Extract conversation details + CiteDCG scores from raw DCG files (unified)\n",
    "2. Build per-utterance details with hop-level scores\n",
    "3. Find paired utterances (for control vs treatment comparison)\n",
    "4. Generate statistics and comparison plots\n",
    "\n",
    "**Output Control**:\n",
    "- The pipeline runs with `verbose=False` for a clean notebook experience\n",
    "- Only essential progress messages are shown\n",
    "- To see full logs for debugging, change `verbose=False` to `verbose=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the unified pipeline function\n",
    "from seval_batch_processor import process_unified_citedcg_with_statistics_plots\n",
    "\n",
    "# Run the unified pipeline - output will display directly\n",
    "result = process_unified_citedcg_with_statistics_plots(\n",
    "    job_id=JOB_ID,\n",
    "    experiment=\"both\",\n",
    "    top_k_list=TOP_K_LIST,\n",
    "    num_threads=NUM_THREADS,\n",
    "    output_base_dir=str(RESULTS_DIR),\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"✓ PROCESSING COMPLETE - READY TO DISPLAY RESULTS\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c374a16",
   "metadata": {},
   "source": [
    "## Step 2: Display Generated Plots\n",
    "\n",
    "View the comparison plots generated by the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c04da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display generated plots (excluding paired utterances plot)\n",
    "stats_dir = RESULTS_DIR / f\"{JOB_ID}_unified_statistics_plots\"\n",
    "\n",
    "if stats_dir.exists():\n",
    "    # Get all plots except the paired utterances plot\n",
    "    all_plots = sorted(stats_dir.glob(\"*.png\"))\n",
    "    plot_files = [p for p in all_plots if 'paired' not in p.name.lower()]\n",
    "    \n",
    "    for plot_file in plot_files:\n",
    "        print(f\"\\n{plot_file.name}\")\n",
    "        print(\"=\"*60)\n",
    "        display(Image(filename=str(plot_file)))\n",
    "else:\n",
    "    print(f\"Plots directory not found: {stats_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6da8f",
   "metadata": {},
   "source": [
    "## Step 3: Statistics Analysis & CSV Export\n",
    "\n",
    "View detailed statistics and export to CSV for further analysis in Excel or other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stats_dir = RESULTS_DIR / f\"{JOB_ID}_unified_statistics_plots\"\n",
    "\n",
    "def export_statistics_to_csv(experiment, k_value):\n",
    "    \"\"\"Export hop statistics to CSV.\"\"\"\n",
    "    stats_file = stats_dir / f\"{JOB_ID}_{experiment}_plot_stats_k{k_value}.json\"\n",
    "    \n",
    "    if not stats_file.exists():\n",
    "        print(f\"Stats file not found: {stats_file}\")\n",
    "        return None\n",
    "    \n",
    "    with open(stats_file, 'r', encoding='utf-8') as f:\n",
    "        stats = json.load(f)\n",
    "    \n",
    "    per_hop = stats.get('per_hop', {})\n",
    "    total_with_scores = stats.get('utterances_with_scores', 0)\n",
    "    total_no_scores = stats.get('utterances_without_any_scores', 0)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    rows = []\n",
    "    for hop in sorted([int(h) for h in per_hop.keys()]):\n",
    "        hop_data = per_hop[str(hop)]\n",
    "        with_scores = hop_data.get('utterances_with_scores', 0)\n",
    "        rows.append({\n",
    "            'Hop': hop,\n",
    "            'Avg_All_Scores': hop_data.get('avg_all_scores'),\n",
    "            'Std_All_Scores': hop_data.get('std_all_scores'),\n",
    "            'Avg_TopK_Scores': hop_data.get('avg_topk_scores'),\n",
    "            'Std_TopK_Scores': hop_data.get('std_topk_scores'),\n",
    "            'With_Scores_At_Hop': with_scores,\n",
    "            'Scores_Elsewhere': total_with_scores - with_scores,\n",
    "            'No_Scores_Anywhere': total_no_scores,\n",
    "            'Total_Utterances': hop_data.get('total_utterances', 0)\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_file = stats_dir / f\"{JOB_ID}_{experiment}_hop_stats_k{k_value}.csv\"\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    \n",
    "    return df, csv_file\n",
    "\n",
    "# Export for all experiments and k-values\n",
    "experiments = ['control', 'treatment']\n",
    "for exp in experiments:\n",
    "    for k in TOP_K_LIST:\n",
    "        result = export_statistics_to_csv(exp, k)\n",
    "        if result is not None:\n",
    "            df, csv_file = result\n",
    "            # Display header with export path together\n",
    "            display(Markdown(f\"### {exp.upper()} - Top-{k}\\n✓ Exported to: `{csv_file.name}`\"))\n",
    "            display(df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
