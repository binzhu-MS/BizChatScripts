{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4781a110",
   "metadata": {},
   "source": [
    "# Reasoning Model Multi-Hop Comparison Report\n",
    "\n",
    "This Jupyter notebook processes SEVAL job data and generates detailed multi-hop comparison reports on reasoning models across control and treatment experiments.\n",
    "\n",
    "**Getting Started**: When you run the configuration cell (cell 4), you can modify the following settings:\n",
    "\n",
    "1. **SEVAL Job ID** (e.g., '133560') – The job ID to analyze\n",
    "2. **Data Paths** (optional) – Override the default paths if your SEVAL data is in a custom location:\n",
    "   - `RAW_DATA_DIR` – Path to scraping raw data output\n",
    "   - `METRICS_DIR` – Path to SEVAL metrics (CiteDCG labels)\n",
    "3. **Top-k Values** – List of top-k values to analyze (e.g., [1, 3, 5]) for ranking metrics\n",
    "4. **Clean Preprocessing** – Set `CLEAN_EXISTING = True` to force regeneration of preprocessing steps\n",
    " \n",
    "**Default Data Structure**:\n",
    "By default, the notebook expects data in the following structure:\n",
    "```\n",
    "seval_data/\n",
    "  {job_id}_scraping_raw_data_output/    # Raw conversation data\n",
    "  {job_id}_metrics/                      # CiteDCG metrics\n",
    "```\n",
    "\n",
    "You can override these paths if your data is located elsewhere (e.g., on a different drive or network location).\n",
    "\n",
    "**What This Notebook Does**:\n",
    "- Extracts CiteDCG scores from SEVAL metrics for both control and treatment\n",
    "- Extracts conversation details and merges with CiteDCG scores\n",
    "- Builds per-utterance statistics aggregated by hop index\n",
    "- Creates comprehensive comparison plots showing:\n",
    "  - Hop-by-hop score progression (including/excluding empty hops)\n",
    "  - Single-hop vs multi-hop performance analysis\n",
    "  - Control vs treatment experiment comparisons\n",
    "- Exports detailed statistics to CSV for further analysis\n",
    "\n",
    "**Prerequisites**: \n",
    "- SEVAL data must be downloaded and available locally (either in default location or custom path)\n",
    "\n",
    "**Processing Behavior**:\n",
    "- **Statistics plots are ALWAYS regenerated** for consistency and to reflect the latest data\n",
    "- Preprocessing steps (CiteDCG extraction, conversation details, merged files) are reused by default for faster processing\n",
    "- Set `CLEAN_EXISTING = True` to force complete regeneration of all preprocessing steps from scratch\n",
    "\n",
    "**Output**: All results are saved to `results/{job_id}_statistics_plots/` including:\n",
    "- Statistics JSON files with hop-level aggregations\n",
    "- PNG plot images for visualization\n",
    "- CSV exports for Excel/data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a12f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules before executing user code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc8e2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modules loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown, Image\n",
    "\n",
    "# Add the seval directory to the path\n",
    "seval_dir = Path.cwd()\n",
    "if str(seval_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(seval_dir))\n",
    "\n",
    "# Add the workspace root to the path for utils module\n",
    "workspace_root = seval_dir.parent.parent  # c:\\working\\BizChatScripts\n",
    "if str(workspace_root) not in sys.path:\n",
    "    sys.path.insert(0, str(workspace_root))\n",
    "\n",
    "print(f\"✓ Added to path: {seval_dir}\")\n",
    "print(f\"✓ Added to path: {workspace_root}\")\n",
    "print(\"✓ Modules loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee27788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Job ID: 133560\n",
      "  Experiment: both (control + treatment)\n",
      "  Top-k values: [1, 3, 5]\n",
      "  Raw data directory: c:\\working\\BizChatScripts\\projects\\seval\\seval_data\\133560_scraping_raw_data_output\n",
      "  Metrics directory: c:\\working\\BizChatScripts\\projects\\seval\\seval_data\\133560_metrics\n",
      "  Output directory: c:\\working\\BizChatScripts\\projects\\seval\\results\n",
      "  Clean preprocessing: False\n",
      "\n",
      "✓ Data directories found\n"
     ]
    }
   ],
   "source": [
    "# Configuration - Modify these values as needed\n",
    "JOB_ID = \"133560\"\n",
    "TOP_K_LIST = [1, 3, 5]  # Top-k values to analyze\n",
    "THREADS = 16\n",
    "CLEAN_EXISTING = False  # Set to True to regenerate preprocessing steps (CiteDCG, conversations, merged)\n",
    "                         # Note: Statistics plots are ALWAYS regenerated\n",
    "\n",
    "# Base directories\n",
    "BASE_DIR = Path.cwd()\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "\n",
    "# SEVAL Data Paths - Override these if your data is in a different location\n",
    "# Default paths assume standard directory structure:\n",
    "#   seval_data/{job_id}_scraping_raw_data_output/\n",
    "#   seval_data/{job_id}_metrics/\n",
    "RAW_DATA_DIR = BASE_DIR / \"seval_data\" / f\"{JOB_ID}_scraping_raw_data_output\"\n",
    "METRICS_DIR = BASE_DIR / \"seval_data\" / f\"{JOB_ID}_metrics\"\n",
    "\n",
    "# Example: Override paths if data is located elsewhere\n",
    "# RAW_DATA_DIR = Path(\"C:/my_data/seval/133560_scraping_raw_data_output\")\n",
    "# METRICS_DIR = Path(\"C:/my_data/seval/133560_metrics\")\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Job ID: {JOB_ID}\")\n",
    "print(f\"  Experiment: both (control + treatment)\")\n",
    "print(f\"  Top-k values: {TOP_K_LIST}\")\n",
    "print(f\"  Raw data directory: {RAW_DATA_DIR}\")\n",
    "print(f\"  Metrics directory: {METRICS_DIR}\")\n",
    "print(f\"  Output directory: {RESULTS_DIR}\")\n",
    "print(f\"  Clean preprocessing: {CLEAN_EXISTING}\")\n",
    "print()\n",
    "\n",
    "# Verify paths exist\n",
    "if not RAW_DATA_DIR.exists():\n",
    "    print(f\"⚠ Warning: Raw data directory not found: {RAW_DATA_DIR}\")\n",
    "if not METRICS_DIR.exists():\n",
    "    print(f\"⚠ Warning: Metrics directory not found: {METRICS_DIR}\")\n",
    "if RAW_DATA_DIR.exists() and METRICS_DIR.exists():\n",
    "    print(\"✓ Data directories found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad2bb6",
   "metadata": {},
   "source": [
    "## Step 1: Run Full SEVAL Processing Pipeline\n",
    "\n",
    "This will execute all steps:\n",
    "1. Extract CiteDCG scores from metrics (reused if CLEAN_EXISTING=False)\n",
    "2. Extract conversation details from raw data (reused if CLEAN_EXISTING=False)\n",
    "3. Merge CiteDCG scores with conversations (reused if CLEAN_EXISTING=False)\n",
    "4. Build per-utterance details with hop-level scores (reused if CLEAN_EXISTING=False)\n",
    "5. Generate statistics and plots (ALWAYS regenerated)\n",
    "\n",
    "**Output Control**:\n",
    "- The pipeline runs with `verbose=False` for a clean notebook experience\n",
    "- Only essential progress messages are shown (what's being processed, completion status)\n",
    "- Detailed processing logs are suppressed (file counts, threading details, etc.)\n",
    "- To see full logs for debugging, change `verbose=False` to `verbose=True` in the cell below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e805f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "014e4790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SEVAL JOB PROCESSING: 133560 (Control + Treatment)\n",
      "================================================================================\n",
      "\n",
      "Cleaning statistics plots directory: c:\\working\\BizChatScripts\\projects\\seval\\results\\133560_statistics_plots\n",
      "✓ Old plots and statistics deleted\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseval_batch_processor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m process_seval_job_with_statistics_plots\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Run the full pipeline\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# verbose=False: Shows only essential progress messages (for notebook/end users)\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# verbose=True: Shows detailed processing logs (for batch processing/developers)\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# clean parameter controls whether to reuse preprocessing (CiteDCG, conversations, merged)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m result = \u001b[43mprocess_seval_job_with_statistics_plots\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mJOB_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mboth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTOP_K_LIST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_data_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mRAW_DATA_DIR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMETRICS_DIR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_base_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mRESULTS_DIR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTHREADS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Minimal output for notebook users\u001b[39;49;00m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclean\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCLEAN_EXISTING\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\working\\BizChatScripts\\projects\\seval\\seval_batch_processor.py:1600\u001b[39m, in \u001b[36mprocess_seval_job_with_statistics_plots\u001b[39m\u001b[34m(job_id, experiment, top_k_list, threads, raw_data_dir, metrics_dir, output_base_dir, clean, verbose)\u001b[39m\n\u001b[32m   1543\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1544\u001b[39m \u001b[33;03mProcess a SEVAL job: extract data, merge with CiteDCG, calculate statistics\u001b[39;00m\n\u001b[32m   1545\u001b[39m \u001b[33;03mfor multiple top-k values, and generate plots.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1596\u001b[39m \u001b[33;03m    from scratch.\u001b[39;00m\n\u001b[32m   1597\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1598\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1600\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mget_seval_metrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extract_per_result_citedcg\n\u001b[32m   1602\u001b[39m \u001b[38;5;66;03m# Parse top-k list - handle both string and tuple/list from Fire\u001b[39;00m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\working\\BizChatScripts\\projects\\seval\\get_seval_metrics.py:79\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfire\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FireExit\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Import from the utils package (sibling folder)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstatistics_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tdiff\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# Add parent directory to path for utils imports\u001b[39;00m\n\u001b[32m     82\u001b[39m sys.path.insert(\u001b[32m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(Path(\u001b[34m__file__\u001b[39m).parent.parent.parent))\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# Run the pipeline with minimal output for notebook\n",
    "print(\"=\"*80)\n",
    "print(f\"SEVAL JOB PROCESSING: {JOB_ID} (Control + Treatment)\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Always clean the statistics plots directory\n",
    "import shutil\n",
    "\n",
    "stats_dir = RESULTS_DIR / f\"{JOB_ID}_statistics_plots\"\n",
    "\n",
    "if stats_dir.exists():\n",
    "    print(f\"Cleaning statistics plots directory: {stats_dir}\")\n",
    "    shutil.rmtree(stats_dir)\n",
    "    print(\"✓ Old plots and statistics deleted\")\n",
    "    print()\n",
    "\n",
    "# Import and run the full pipeline\n",
    "from seval_batch_processor import process_seval_job_with_statistics_plots\n",
    "\n",
    "# Run the full pipeline\n",
    "# verbose=False: Shows only essential progress messages (for notebook/end users)\n",
    "# verbose=True: Shows detailed processing logs (for batch processing/developers)\n",
    "# clean parameter controls whether to reuse preprocessing (CiteDCG, conversations, merged)\n",
    "result = process_seval_job_with_statistics_plots(\n",
    "    job_id=JOB_ID,\n",
    "    experiment=\"both\",\n",
    "    top_k_list=TOP_K_LIST,\n",
    "    raw_data_dir=str(RAW_DATA_DIR),\n",
    "    metrics_dir=str(METRICS_DIR),\n",
    "    output_base_dir=str(RESULTS_DIR),\n",
    "    threads=THREADS,\n",
    "    verbose=False,  # Minimal output for notebook users\n",
    "    clean=CLEAN_EXISTING\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"✓ PROCESSING COMPLETE - READY TO DISPLAY RESULTS\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c374a16",
   "metadata": {},
   "source": [
    "## Step 2: Display Generated Statistics\n",
    "\n",
    "View the statistics for each experiment and top-k value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c04da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistics summary\n",
    "stats_dir = RESULTS_DIR / f\"{JOB_ID}_statistics_plots\"\n",
    "\n",
    "def display_stats_summary(stats_file):\n",
    "    \"\"\"Display summary statistics from a stats JSON file.\"\"\"\n",
    "    with open(stats_file, 'r', encoding='utf-8') as f:\n",
    "        stats = json.load(f)\n",
    "    \n",
    "    print(f\"\\nStatistics from: {stats_file.name}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Top-k: {stats.get('top_k')}\")\n",
    "    print(f\"Total utterances: {stats.get('total_utterances')}\")\n",
    "    print(f\"Utterances with scores: {stats.get('utterances_with_scores')}\")\n",
    "    \n",
    "    # Per-hop statistics\n",
    "    per_hop = stats.get('per_hop', {})\n",
    "    if per_hop:\n",
    "        print(f\"\\nPer-Hop Statistics (first 5 hops):\")\n",
    "        for hop in sorted([int(h) for h in per_hop.keys()])[:5]:\n",
    "            hop_data = per_hop[str(hop)]\n",
    "            avg = hop_data.get('avg_all_scores')\n",
    "            count = hop_data.get('utterances_with_scores', 0)\n",
    "            avg_str = f\"{avg:.4f}\" if avg is not None else \"N/A\"\n",
    "            print(f\"  Hop {hop}: avg={avg_str}, count={count}\")\n",
    "    \n",
    "    # Single vs Multi-hop\n",
    "    single = stats.get('single_hop', {})\n",
    "    multi = stats.get('multi_hop', {})\n",
    "    if single:\n",
    "        single_data = single.get('1', {})\n",
    "        print(f\"\\nSingle-hop utterances: {single_data.get('utterances_count', 0)}\")\n",
    "        print(f\"  Avg score: {single_data.get('avg_all_scores', 0):.4f}\")\n",
    "    if multi:\n",
    "        multi_count = sum(h.get('utterances_count', 0) for h in multi.values())\n",
    "        print(f\"Multi-hop utterances: {multi_count}\")\n",
    "\n",
    "# Display stats for each experiment and k-value\n",
    "if stats_dir.exists():\n",
    "    for stats_file in sorted(stats_dir.glob(\"*_plot_stats_k*.json\")):\n",
    "        display_stats_summary(stats_file)\n",
    "else:\n",
    "    print(f\"Statistics directory not found: {stats_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e952fb",
   "metadata": {},
   "source": [
    "## Step 3: Display Generated Plots\n",
    "\n",
    "View the comparison plots generated by the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d3db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display generated plots (excluding paired utterances plot)\n",
    "if stats_dir.exists():\n",
    "    # Get all plots except the paired utterances plot\n",
    "    all_plots = sorted(stats_dir.glob(\"*.png\"))\n",
    "    plot_files = [p for p in all_plots if 'paired' not in p.name.lower()]\n",
    "    \n",
    "    for plot_file in plot_files:\n",
    "        print(f\"\\n{plot_file.name}\")\n",
    "        print(\"=\"*60)\n",
    "        display(Image(filename=str(plot_file)))\n",
    "else:\n",
    "    print(f\"Plots directory not found: {stats_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6da8f",
   "metadata": {},
   "source": [
    "## Step 4: Detailed Statistics Analysis\n",
    "\n",
    "Examine specific statistics in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze specific statistics\n",
    "def analyze_hop_statistics(experiment, k_value):\n",
    "    \"\"\"Analyze hop-level statistics for a specific experiment and k-value.\"\"\"\n",
    "    stats_file = stats_dir / f\"{JOB_ID}_{experiment}_plot_stats_k{k_value}.json\"\n",
    "    \n",
    "    if not stats_file.exists():\n",
    "        print(f\"Stats file not found: {stats_file}\")\n",
    "        return\n",
    "    \n",
    "    with open(stats_file, 'r', encoding='utf-8') as f:\n",
    "        stats = json.load(f)\n",
    "    \n",
    "    print(f\"\\nDetailed Hop Statistics: {experiment.upper()} (k={k_value})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    per_hop = stats.get('per_hop', {})\n",
    "    \n",
    "    # Create summary table\n",
    "    print(f\"{'Hop':<6} {'Avg Score':<12} {'Std Dev':<12} {'With Scores':<15} {'Without Scores':<15} {'Total':<10}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for hop in sorted([int(h) for h in per_hop.keys()]):\n",
    "        hop_data = per_hop[str(hop)]\n",
    "        avg = hop_data.get('avg_all_scores')\n",
    "        std = hop_data.get('std_all_scores')\n",
    "        with_scores = hop_data.get('utterances_with_scores', 0)\n",
    "        without_scores = hop_data.get('utterances_without_scores', 0)\n",
    "        total = hop_data.get('total_utterances', 0)\n",
    "        \n",
    "        avg_str = f\"{avg:.4f}\" if avg is not None else \"N/A\"\n",
    "        std_str = f\"{std:.4f}\" if std is not None else \"N/A\"\n",
    "        \n",
    "        print(f\"{hop:<6} {avg_str:<12} {std_str:<12} {with_scores:<15} {without_scores:<15} {total:<10}\")\n",
    "\n",
    "# Analyze statistics for both control and treatment experiments\n",
    "experiments = ['control', 'treatment']\n",
    "for exp in experiments:\n",
    "    for k in TOP_K_LIST:\n",
    "        analyze_hop_statistics(exp, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848244d7",
   "metadata": {},
   "source": [
    "## Step 5: Export Statistics to CSV (Optional)\n",
    "\n",
    "Export statistics to CSV format for further analysis in Excel or other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def export_statistics_to_csv(experiment, k_value):\n",
    "    \"\"\"Export hop statistics to CSV.\"\"\"\n",
    "    stats_file = stats_dir / f\"{JOB_ID}_{experiment}_plot_stats_k{k_value}.json\"\n",
    "    \n",
    "    if not stats_file.exists():\n",
    "        print(f\"Stats file not found: {stats_file}\")\n",
    "        return\n",
    "    \n",
    "    with open(stats_file, 'r', encoding='utf-8') as f:\n",
    "        stats = json.load(f)\n",
    "    \n",
    "    per_hop = stats.get('per_hop', {})\n",
    "    \n",
    "    # Create DataFrame\n",
    "    rows = []\n",
    "    for hop in sorted([int(h) for h in per_hop.keys()]):\n",
    "        hop_data = per_hop[str(hop)]\n",
    "        rows.append({\n",
    "            'Hop': hop,\n",
    "            'Avg_All_Scores': hop_data.get('avg_all_scores'),\n",
    "            'Std_All_Scores': hop_data.get('std_all_scores'),\n",
    "            'Avg_TopK_Scores': hop_data.get('avg_topk_scores'),\n",
    "            'Std_TopK_Scores': hop_data.get('std_topk_scores'),\n",
    "            'Utterances_With_Scores': hop_data.get('utterances_with_scores', 0),\n",
    "            'Utterances_Without_Scores': hop_data.get('utterances_without_scores', 0),\n",
    "            'Total_Utterances': hop_data.get('total_utterances', 0)\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_file = stats_dir / f\"{JOB_ID}_{experiment}_hop_stats_k{k_value}.csv\"\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"✓ Exported to: {csv_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Export for all experiments and k-values\n",
    "for exp in experiments:\n",
    "    for k in TOP_K_LIST:\n",
    "        df = export_statistics_to_csv(exp, k)\n",
    "        if df is not None:\n",
    "            display(Markdown(f\"### {exp.upper()} - Top-{k}\"))\n",
    "            display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b80e3a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "1. ✓ Processed SEVAL job data through the complete pipeline\n",
    "2. ✓ Generated statistics for multiple top-k values\n",
    "3. ✓ Created comparison plots (hop index, hop sequence, single vs multi-hop)\n",
    "4. ✓ Displayed statistics and visualizations\n",
    "5. ✓ Exported data to CSV for further analysis\n",
    "\n",
    "**Output Files:**\n",
    "- Statistics JSON files: `results/{JOB_ID}_statistics_plots/*_plot_stats_k*.json`\n",
    "- Plot images: `results/{JOB_ID}_statistics_plots/*.png`\n",
    "- CSV exports: `results/{JOB_ID}_statistics_plots/*_hop_stats_k*.csv`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
