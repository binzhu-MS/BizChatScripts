{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4781a110",
   "metadata": {},
   "source": [
    "# Reasoning Model Multi-Hop Comparison Report\n",
    "\n",
    "This Jupyter notebook will process SEVAL job data and generate comprehensive multi-hop comparison reports with statistics and visualizations for both control and treatment experiments.\n",
    "\n",
    "**Getting Started**: When you run the configuration cell (cell 3), you can modify the following settings:\n",
    "\n",
    "1. **SEVAL Job ID** (e.g., '133560') – The job ID to analyze\n",
    "2. **Top-k Values** – List of top-k values to analyze (e.g., [1, 3, 5]) for ranking metrics\n",
    "3. **Data Paths** (optional) – Override the default paths if your SEVAL data is in a custom location:\n",
    "   - `RAW_DATA_DIR` – Path to scraping raw data output\n",
    "   - `METRICS_DIR` – Path to SEVAL metrics (CiteDCG labels)\n",
    "\n",
    "**Default Data Structure**:\n",
    "By default, the notebook expects data in the following structure:\n",
    "```\n",
    "seval_data/\n",
    "  {job_id}_scraping_raw_data_output/    # Raw conversation data\n",
    "  {job_id}_metrics/                      # CiteDCG metrics\n",
    "```\n",
    "\n",
    "You can override these paths if your data is located elsewhere (e.g., on a different drive or network location).\n",
    "\n",
    "**What This Notebook Does**:\n",
    "- Extracts CiteDCG scores from SEVAL metrics for both control and treatment\n",
    "- Extract conversation details and merges with CiteDCG scores\n",
    "- Generates per-utterance statistics aggregated by hop index\n",
    "- Creates comprehensive comparison plots showing:\n",
    "  - Hop-by-hop score progression (including/excluding empty hops)\n",
    "  - Single-hop vs multi-hop performance analysis\n",
    "  - Control vs treatment experiment comparisons\n",
    "- Exports detailed statistics to CSV for further analysis\n",
    "\n",
    "**Prerequisites**: \n",
    "- SEVAL data must be downloaded and available locally (either in default location or custom path)\n",
    "- If result files already exist in the `results` directory, the notebook will reuse them for faster processing\n",
    "- Set `CLEAN_EXISTING = True` to force regeneration of all intermediate files\n",
    "\n",
    "**Output**: All results are saved to `results/{job_id}_statistics_plots/` including:\n",
    "- Statistics JSON files with hop-level aggregations\n",
    "- PNG plot images for visualization\n",
    "- CSV exports for Excel/data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a12f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules before executing user code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc8e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown, Image\n",
    "\n",
    "# Add the seval directory to the path\n",
    "seval_dir = Path.cwd()\n",
    "if str(seval_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(seval_dir))\n",
    "\n",
    "print(\"✓ Modules loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee27788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Modify these values as needed\n",
    "JOB_ID = \"133560\"\n",
    "TOP_K_LIST = [1, 3, 5]  # Top-k values to analyze\n",
    "THREADS = 16\n",
    "CLEAN_EXISTING = False  # Set to True to force regeneration of all files\n",
    "\n",
    "# Base directories\n",
    "BASE_DIR = Path.cwd()\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "\n",
    "# SEVAL Data Paths - Override these if your data is in a different location\n",
    "# Default paths assume standard directory structure:\n",
    "#   seval_data/{job_id}_scraping_raw_data_output/\n",
    "#   seval_data/{job_id}_metrics/\n",
    "RAW_DATA_DIR = BASE_DIR / \"seval_data\" / f\"{JOB_ID}_scraping_raw_data_output\"\n",
    "METRICS_DIR = BASE_DIR / \"seval_data\" / f\"{JOB_ID}_metrics\"\n",
    "\n",
    "# Example: Override paths if data is located elsewhere\n",
    "# RAW_DATA_DIR = Path(\"C:/my_data/seval/133560_scraping_raw_data_output\")\n",
    "# METRICS_DIR = Path(\"C:/my_data/seval/133560_metrics\")\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Job ID: {JOB_ID}\")\n",
    "print(f\"  Experiment: both (control + treatment)\")\n",
    "print(f\"  Top-k values: {TOP_K_LIST}\")\n",
    "print(f\"  Raw data directory: {RAW_DATA_DIR}\")\n",
    "print(f\"  Metrics directory: {METRICS_DIR}\")\n",
    "print(f\"  Output directory: {RESULTS_DIR}\")\n",
    "print()\n",
    "\n",
    "# Verify paths exist\n",
    "if not RAW_DATA_DIR.exists():\n",
    "    print(f\"⚠ Warning: Raw data directory not found: {RAW_DATA_DIR}\")\n",
    "if not METRICS_DIR.exists():\n",
    "    print(f\"⚠ Warning: Metrics directory not found: {METRICS_DIR}\")\n",
    "if RAW_DATA_DIR.exists() and METRICS_DIR.exists():\n",
    "    print(\"✓ Data directories found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad2bb6",
   "metadata": {},
   "source": [
    "## Step 1: Run Full SEVAL Processing Pipeline\n",
    "\n",
    "This will execute all steps:\n",
    "1. Extract CiteDCG scores from metrics\n",
    "2. Extract conversation details from raw data\n",
    "3. Merge CiteDCG scores with conversations\n",
    "4. Build per-utterance details with hop-level scores\n",
    "5. Generate statistics and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline with minimal output for notebook\n",
    "print(\"=\"*80)\n",
    "print(f\"SEVAL JOB PROCESSING: {JOB_ID} (Control + Treatment)\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Check if we need to run the pipeline or can reuse existing results\n",
    "stats_dir = RESULTS_DIR / f\"{JOB_ID}_statistics_plots\"\n",
    "need_processing = CLEAN_EXISTING or not stats_dir.exists()\n",
    "\n",
    "if not need_processing:\n",
    "    # Check if we have all the required statistics files\n",
    "    for exp in ['control', 'treatment']:\n",
    "        for k in TOP_K_LIST:\n",
    "            stats_file = stats_dir / f\"{JOB_ID}_{exp}_plot_stats_k{k}.json\"\n",
    "            if not stats_file.exists():\n",
    "                need_processing = True\n",
    "                break\n",
    "        if need_processing:\n",
    "            break\n",
    "\n",
    "if need_processing:\n",
    "    print(\"Processing SEVAL data...\")\n",
    "    print()\n",
    "    \n",
    "    # Import required functions\n",
    "    from seval_batch_processor import process_seval_job_with_statistics_plots\n",
    "    \n",
    "    # Run the full pipeline (note: this will generate paired plot but we won't display it)\n",
    "    result = process_seval_job_with_statistics_plots(\n",
    "        job_id=JOB_ID,\n",
    "        experiment=\"both\",\n",
    "        top_k_list=TOP_K_LIST,\n",
    "        raw_data_dir=str(RAW_DATA_DIR),\n",
    "        metrics_dir=str(METRICS_DIR),\n",
    "        output_base_dir=str(RESULTS_DIR),\n",
    "        threads=THREADS,\n",
    "        verbose=False,\n",
    "        clean_existing=CLEAN_EXISTING\n",
    "    )\n",
    "else:\n",
    "    print(\"✓ Using existing processed data\")\n",
    "    print(f\"  Location: {stats_dir}\")\n",
    "    print()\n",
    "    print(\"  Set CLEAN_EXISTING = True in the configuration cell to force reprocessing\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"✓ READY TO DISPLAY RESULTS\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c374a16",
   "metadata": {},
   "source": [
    "## Step 2: Display Generated Statistics\n",
    "\n",
    "View the statistics for each experiment and top-k value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c04da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistics summary\n",
    "stats_dir = RESULTS_DIR / f\"{JOB_ID}_statistics_plots\"\n",
    "\n",
    "def display_stats_summary(stats_file):\n",
    "    \"\"\"Display summary statistics from a stats JSON file.\"\"\"\n",
    "    with open(stats_file, 'r', encoding='utf-8') as f:\n",
    "        stats = json.load(f)\n",
    "    \n",
    "    print(f\"\\nStatistics from: {stats_file.name}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Top-k: {stats.get('top_k')}\")\n",
    "    print(f\"Total utterances: {stats.get('total_utterances')}\")\n",
    "    print(f\"Utterances with scores: {stats.get('utterances_with_scores')}\")\n",
    "    \n",
    "    # Per-hop statistics\n",
    "    per_hop = stats.get('per_hop', {})\n",
    "    if per_hop:\n",
    "        print(f\"\\nPer-Hop Statistics (first 5 hops):\")\n",
    "        for hop in sorted([int(h) for h in per_hop.keys()])[:5]:\n",
    "            hop_data = per_hop[str(hop)]\n",
    "            avg = hop_data.get('avg_all_scores')\n",
    "            count = hop_data.get('utterances_with_scores', 0)\n",
    "            avg_str = f\"{avg:.4f}\" if avg is not None else \"N/A\"\n",
    "            print(f\"  Hop {hop}: avg={avg_str}, count={count}\")\n",
    "    \n",
    "    # Single vs Multi-hop\n",
    "    single = stats.get('single_hop', {})\n",
    "    multi = stats.get('multi_hop', {})\n",
    "    if single:\n",
    "        single_data = single.get('1', {})\n",
    "        print(f\"\\nSingle-hop utterances: {single_data.get('utterances_count', 0)}\")\n",
    "        print(f\"  Avg score: {single_data.get('avg_all_scores', 0):.4f}\")\n",
    "    if multi:\n",
    "        multi_count = sum(h.get('utterances_count', 0) for h in multi.values())\n",
    "        print(f\"Multi-hop utterances: {multi_count}\")\n",
    "\n",
    "# Display stats for each experiment and k-value\n",
    "if stats_dir.exists():\n",
    "    for stats_file in sorted(stats_dir.glob(\"*_plot_stats_k*.json\")):\n",
    "        display_stats_summary(stats_file)\n",
    "else:\n",
    "    print(f\"Statistics directory not found: {stats_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e952fb",
   "metadata": {},
   "source": [
    "## Step 3: Display Generated Plots\n",
    "\n",
    "View the comparison plots generated by the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d3db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display generated plots (excluding paired utterances plot)\n",
    "if stats_dir.exists():\n",
    "    # Get all plots except the paired utterances plot\n",
    "    all_plots = sorted(stats_dir.glob(\"*.png\"))\n",
    "    plot_files = [p for p in all_plots if 'paired' not in p.name.lower()]\n",
    "    \n",
    "    for plot_file in plot_files:\n",
    "        print(f\"\\n{plot_file.name}\")\n",
    "        print(\"=\"*60)\n",
    "        display(Image(filename=str(plot_file)))\n",
    "else:\n",
    "    print(f\"Plots directory not found: {stats_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6da8f",
   "metadata": {},
   "source": [
    "## Step 4: Detailed Statistics Analysis\n",
    "\n",
    "Examine specific statistics in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze specific statistics\n",
    "def analyze_hop_statistics(experiment, k_value):\n",
    "    \"\"\"Analyze hop-level statistics for a specific experiment and k-value.\"\"\"\n",
    "    stats_file = stats_dir / f\"{JOB_ID}_{experiment}_plot_stats_k{k_value}.json\"\n",
    "    \n",
    "    if not stats_file.exists():\n",
    "        print(f\"Stats file not found: {stats_file}\")\n",
    "        return\n",
    "    \n",
    "    with open(stats_file, 'r', encoding='utf-8') as f:\n",
    "        stats = json.load(f)\n",
    "    \n",
    "    print(f\"\\nDetailed Hop Statistics: {experiment.upper()} (k={k_value})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    per_hop = stats.get('per_hop', {})\n",
    "    \n",
    "    # Create summary table\n",
    "    print(f\"{'Hop':<6} {'Avg Score':<12} {'Std Dev':<12} {'With Scores':<15} {'Without Scores':<15} {'Total':<10}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for hop in sorted([int(h) for h in per_hop.keys()]):\n",
    "        hop_data = per_hop[str(hop)]\n",
    "        avg = hop_data.get('avg_all_scores')\n",
    "        std = hop_data.get('std_all_scores')\n",
    "        with_scores = hop_data.get('utterances_with_scores', 0)\n",
    "        without_scores = hop_data.get('utterances_without_scores', 0)\n",
    "        total = hop_data.get('total_utterances', 0)\n",
    "        \n",
    "        avg_str = f\"{avg:.4f}\" if avg is not None else \"N/A\"\n",
    "        std_str = f\"{std:.4f}\" if std is not None else \"N/A\"\n",
    "        \n",
    "        print(f\"{hop:<6} {avg_str:<12} {std_str:<12} {with_scores:<15} {without_scores:<15} {total:<10}\")\n",
    "\n",
    "# Analyze statistics for both control and treatment experiments\n",
    "experiments = ['control', 'treatment']\n",
    "for exp in experiments:\n",
    "    for k in TOP_K_LIST:\n",
    "        analyze_hop_statistics(exp, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848244d7",
   "metadata": {},
   "source": [
    "## Step 5: Export Statistics to CSV (Optional)\n",
    "\n",
    "Export statistics to CSV format for further analysis in Excel or other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def export_statistics_to_csv(experiment, k_value):\n",
    "    \"\"\"Export hop statistics to CSV.\"\"\"\n",
    "    stats_file = stats_dir / f\"{JOB_ID}_{experiment}_plot_stats_k{k_value}.json\"\n",
    "    \n",
    "    if not stats_file.exists():\n",
    "        print(f\"Stats file not found: {stats_file}\")\n",
    "        return\n",
    "    \n",
    "    with open(stats_file, 'r', encoding='utf-8') as f:\n",
    "        stats = json.load(f)\n",
    "    \n",
    "    per_hop = stats.get('per_hop', {})\n",
    "    \n",
    "    # Create DataFrame\n",
    "    rows = []\n",
    "    for hop in sorted([int(h) for h in per_hop.keys()]):\n",
    "        hop_data = per_hop[str(hop)]\n",
    "        rows.append({\n",
    "            'Hop': hop,\n",
    "            'Avg_All_Scores': hop_data.get('avg_all_scores'),\n",
    "            'Std_All_Scores': hop_data.get('std_all_scores'),\n",
    "            'Avg_TopK_Scores': hop_data.get('avg_topk_scores'),\n",
    "            'Std_TopK_Scores': hop_data.get('std_topk_scores'),\n",
    "            'Utterances_With_Scores': hop_data.get('utterances_with_scores', 0),\n",
    "            'Utterances_Without_Scores': hop_data.get('utterances_without_scores', 0),\n",
    "            'Total_Utterances': hop_data.get('total_utterances', 0)\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_file = stats_dir / f\"{JOB_ID}_{experiment}_hop_stats_k{k_value}.csv\"\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"✓ Exported to: {csv_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Export for all experiments and k-values\n",
    "for exp in experiments:\n",
    "    for k in TOP_K_LIST:\n",
    "        df = export_statistics_to_csv(exp, k)\n",
    "        if df is not None:\n",
    "            display(Markdown(f\"### {exp.upper()} - Top-{k}\"))\n",
    "            display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b80e3a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has:\n",
    "1. ✓ Processed SEVAL job data through the complete pipeline\n",
    "2. ✓ Generated statistics for multiple top-k values\n",
    "3. ✓ Created comparison plots (hop index, hop sequence, single vs multi-hop)\n",
    "4. ✓ Displayed statistics and visualizations\n",
    "5. ✓ Exported data to CSV for further analysis\n",
    "\n",
    "**Output Files:**\n",
    "- Statistics JSON files: `results/{JOB_ID}_statistics_plots/*_plot_stats_k*.json`\n",
    "- Plot images: `results/{JOB_ID}_statistics_plots/*.png`\n",
    "- CSV exports: `results/{JOB_ID}_statistics_plots/*_hop_stats_k*.csv`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
